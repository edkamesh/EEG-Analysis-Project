{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c98468-3a1a-49bb-9d5b-4c05851aaf3a",
   "metadata": {},
   "source": [
    "## EEG Data Preprocessing and EEGNet Model Training\n",
    "### Introduction\n",
    "\n",
    "This documentation provides a step-by-step guide on how to preprocess EEG data from EDF files, segment the data, and train an EEGNet model using TensorFlow/Keras. The dataset used is from the PhysioNet EEG recordings of subjects before and during mental arithmetic tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e380368c-4ae5-42de-bcc1-76a7c671a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import resample\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ec33c-a400-46f1-97f0-693f382c4a3d",
   "metadata": {},
   "source": [
    "## Step 1: Loading EDF Files and Extracting Signals\n",
    "### Objective: Load EEG data from EDF files and extract the signals into numpy arrays.\n",
    "\n",
    "Explanation: EDF (European Data Format) files are commonly used for storing EEG data. The MNE library in Python is a powerful tool for loading and manipulating EEG data from EDF files. In this step, we read the EDF files from the specified folder, extract the EEG signals, and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41030143-e355-47bd-bcb3-ee174e44f5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_raw shape: (72, 21, 94000)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and Extract Signals from EDF Files\n",
    "def load_edf_files(folder_path):\n",
    "    edf_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.edf')]\n",
    "    all_signals = []\n",
    "    max_samples = 0\n",
    "    \n",
    "    # Determine the maximum number of samples across all files\n",
    "    for edf_file in edf_files:\n",
    "        edf_reader = pyedflib.EdfReader(edf_file)\n",
    "        max_samples = max(max_samples, edf_reader.getNSamples()[0])\n",
    "        edf_reader.close()\n",
    "    \n",
    "    for edf_file in edf_files:\n",
    "        edf_reader = pyedflib.EdfReader(edf_file)\n",
    "        num_channels = edf_reader.signals_in_file\n",
    "        signals = np.zeros((num_channels, max_samples))\n",
    "        \n",
    "        for i in range(num_channels):\n",
    "            signal = edf_reader.readSignal(i)\n",
    "            if len(signal) < max_samples:\n",
    "                # Pad with zeros if the signal is shorter than the max_samples\n",
    "                signal = np.pad(signal, (0, max_samples - len(signal)), 'constant')\n",
    "            signals[i, :] = signal\n",
    "        \n",
    "        all_signals.append(signals)\n",
    "        edf_reader.close()\n",
    "    \n",
    "    return np.array(all_signals), edf_files\n",
    "\n",
    "folder_path = \"C:/Users/kames/Downloads/eeg-during-mental-arithmetic-tasks-1.0.0/eeg-during-mental-arithmetic-tasks-1.0.0\"\n",
    "X_raw, edf_files = load_edf_files(folder_path)\n",
    "print(f\"X_raw shape: {X_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652b03d4-2a64-41da-8be9-903c06cfdd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_raw shape: (72,)\n",
      "y_raw: [0 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load subject information\n",
    "subject_info = pd.read_csv(\"C:/Users/kames/Downloads/subject-info.csv\")\n",
    "\n",
    "# Extract labels (assuming 'Count quality' is the column for labels)\n",
    "labels_dict = {str(row['Subject']): row['Count quality'] for _, row in subject_info.iterrows()}\n",
    "\n",
    "# Extract labels from file names\n",
    "def get_labels(edf_files, labels_dict):\n",
    "    labels = []\n",
    "    for file in edf_files:\n",
    "        subject_id = os.path.basename(file).split('_')[0]\n",
    "        if subject_id in labels_dict:\n",
    "            labels.append(labels_dict[subject_id])\n",
    "        else:\n",
    "            labels.append(None)  # Handle missing labels if necessary\n",
    "    return np.array(labels)\n",
    "\n",
    "y_raw = get_labels(edf_files, labels_dict)\n",
    "print(f\"y_raw shape: {y_raw.shape}\")\n",
    "print(f\"y_raw: {y_raw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94add22-23bd-4694-b405-418116b50acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_scaled shape: (72, 94000, 21, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_signals(signals):\n",
    "    # Transpose to have shape (samples, channels, time_points)\n",
    "    signals = np.transpose(signals, (0, 2, 1))\n",
    "    \n",
    "    # Reshape for CNN input (samples, channels, time_points, 1)\n",
    "    samples, time_points, channels = signals.shape\n",
    "    signals = signals.reshape(samples, time_points, channels, 1)\n",
    "    \n",
    "    # Normalize\n",
    "    scaler = StandardScaler()\n",
    "    signals_scaled = scaler.fit_transform(signals.reshape(-1, channels)).reshape(signals.shape)\n",
    "    \n",
    "    return signals_scaled\n",
    "\n",
    "X_scaled = preprocess_signals(X_raw)\n",
    "print(f\"X_scaled shape: {X_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51fa31e-84e4-4e10-b5f7-5f744f11cf3c",
   "metadata": {},
   "source": [
    "## Step 2: Downsampling the Signals\n",
    "### Objective: Reduce the sampling rate of the EEG signals to make the data more manageable for processing.\n",
    "\n",
    "Explanation: EEG data often comes with a high sampling rate, such as 1000 Hz, which means there are 1000 data points per second. Downsampling reduces the number of data points, making it easier to handle computationally. Here, we downsample the signals from 1000 Hz to 250 Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ff6834-50d5-4206-b3ca-3129c035936d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_downsampled shape: (72, 21, 23500)\n"
     ]
    }
   ],
   "source": [
    "from scipy.signal import resample\n",
    "\n",
    "def downsample_signals(signals, target_length):\n",
    "    downsampled_signals = []\n",
    "    for signal in signals:\n",
    "        num_channels = signal.shape[0]\n",
    "        downsampled_signal = np.zeros((num_channels, target_length))\n",
    "        for i in range(num_channels):\n",
    "            downsampled_signal[i, :] = resample(signal[i, :], target_length)\n",
    "        downsampled_signals.append(downsampled_signal)\n",
    "    return np.array(downsampled_signals)\n",
    "\n",
    "# Assuming we want to downsample to 250 Hz from 1000 Hz and the original length is 94000 (for 60 seconds at 1000 Hz)\n",
    "original_length = 94000\n",
    "target_length = int(original_length * 250 / 1000)\n",
    "\n",
    "X_downsampled = downsample_signals(X_raw, target_length)\n",
    "print(f\"X_downsampled shape: {X_downsampled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814c922-1123-4a8f-be23-b2a9f704f78a",
   "metadata": {},
   "source": [
    "## Step 3: Segmenting the Signals\n",
    "### Objective: Split the continuous EEG signals into shorter, fixed-length segments.\n",
    "\n",
    "Explanation: Segmenting the EEG data into shorter chunks (e.g., 1-second segments) can improve the performance of machine learning models by providing more training samples. Overlapping segments can also be used to increase the dataset size further. In this step, we split the signals into 1-second segments with a 50% overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb815d67-8b23-42b7-88b5-1906685852ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_segmented shape: (13464, 21, 250)\n"
     ]
    }
   ],
   "source": [
    "def segment_signals(signals, segment_length, overlap):\n",
    "    segments = []\n",
    "    for signal in signals:\n",
    "        num_channels, num_time_points = signal.shape\n",
    "        for start in range(0, num_time_points - segment_length + 1, segment_length // overlap):\n",
    "            segments.append(signal[:, start:start + segment_length])\n",
    "    return np.array(segments)\n",
    "\n",
    "segment_length = 250  # 1 second segments\n",
    "overlap = 2  # 50% overlap\n",
    "\n",
    "X_segmented = segment_signals(X_downsampled, segment_length, overlap)\n",
    "print(f\"X_segmented shape: {X_segmented.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482d84aa-c24d-434e-a577-10eb1bbbcba8",
   "metadata": {},
   "source": [
    "## Step 4: Preprocessing the Signals\n",
    "### Objective: Normalize and reshape the segmented signals to prepare them for input into the neural network.\n",
    "\n",
    "Explanation: Normalization ensures that the features have similar scales, which helps in faster convergence during training. The segmented signals are reshaped to match the input shape expected by the EEGNet model, which is (samples, time points, channels, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0d73fc7-dab7-43d6-99b5-010efa38eb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_preprocessed shape: (13464, 250, 21, 1)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_signals(signals):\n",
    "    samples, channels, time_points = signals.shape\n",
    "    signals = signals.transpose((0, 2, 1)).reshape(samples, time_points, channels, 1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    signals_scaled = scaler.fit_transform(signals.reshape(-1, channels)).reshape(signals.shape)\n",
    "    \n",
    "    return signals_scaled\n",
    "\n",
    "X_preprocessed = preprocess_signals(X_segmented)\n",
    "print(f\"X_preprocessed shape: {X_preprocessed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49291e09-cb63-47f3-9371-7b525fd52301",
   "metadata": {},
   "source": [
    "## Step 5: Creating Labels\n",
    "### Objective: Ensure that each segmented signal has a corresponding label.\n",
    "\n",
    "Explanation: Since we have segmented the data, we need to repeat the labels for each segment. This step ensures that each segment has a label corresponding to its original signal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd150cbf-3190-474c-bcd9-c6eccf7dc2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_repeated shape: (13464,)\n"
     ]
    }
   ],
   "source": [
    "# Repeat labels to match the number of segments per original sample\n",
    "num_segments_per_sample = X_segmented.shape[0] // len(X_downsampled)\n",
    "y_repeated = np.repeat(y_raw, num_segments_per_sample)\n",
    "print(f\"y_repeated shape: {y_repeated.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b07c32-ac81-48cf-bcb1-4bcd3f2ea68c",
   "metadata": {},
   "source": [
    "## Step 6: Splitting the Dataset\n",
    "### Objective: Split the dataset into training and testing sets.\n",
    "\n",
    "Explanation: To evaluate the performance of the model, we need to separate the data into training and testing sets. The training set is used to train the model, while the testing set is used to evaluate its performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8e9e63-b1b6-44ce-a307-25fb670f70f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10771, 250, 21, 1)\n",
      "X_test shape: (2693, 250, 21, 1)\n",
      "y_train shape: (10771,)\n",
      "y_test shape: (2693,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_repeated, test_size=0.2, random_state=42)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b2d08-e543-4f54-973b-3c28f59f24d7",
   "metadata": {},
   "source": [
    "## Step 7: Define the TSCeption Model\n",
    "### Objective: Implement the TSCeption model architecture.\n",
    "\n",
    "Explanation: The TSCeption model consists of multiple branches of convolutional layers that capture temporal features at different scales. These features are then concatenated and passed through additional convolutional layers to capture spatial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32b4c086-8431-469d-8f72-4d4efa15db47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │ spatial_dropout1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],            │\n",
       "│                               │                           │                 │ spatial_dropout1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │ spatial_dropout1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],               │\n",
       "│                               │                           │                 │ spatial_dropout1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m21\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │              \u001b[38;5;34m64\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │             \u001b[38;5;34m784\u001b[0m │ spatial_dropout1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │              \u001b[38;5;34m64\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │             \u001b[38;5;34m352\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],            │\n",
       "│                               │                           │                 │ spatial_dropout1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │             \u001b[38;5;34m784\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │              \u001b[38;5;34m64\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │             \u001b[38;5;34m784\u001b[0m │ spatial_dropout1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │              \u001b[38;5;34m64\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],               │\n",
       "│                               │                           │                 │ spatial_dropout1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                 │              \u001b[38;5;34m34\u001b[0m │ global_average_pooling1d_… │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,018</span> (15.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,018\u001b[0m (15.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,890</span> (15.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,890\u001b[0m (15.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, SpatialDropout1D, Add, Dense, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def TCN(input_shape, num_classes, num_filters=32, kernel_size=3, dilation_rates=[1, 2, 4], dropout_rate=0.2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    for dilation_rate in dilation_rates:\n",
    "        prev_x = x\n",
    "        x = Conv1D(filters=num_filters, kernel_size=kernel_size, padding='causal', dilation_rate=dilation_rate)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        \n",
    "        x = Conv1D(filters=num_filters, kernel_size=kernel_size, padding='causal', dilation_rate=dilation_rate)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = SpatialDropout1D(rate=dropout_rate)(x)\n",
    "        \n",
    "        if prev_x.shape[-1] != x.shape[-1]:\n",
    "            prev_x = Conv1D(filters=num_filters, kernel_size=1, padding='same')(prev_x)\n",
    "        \n",
    "        x = Add()([prev_x, x])\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Define input shape based on your data\n",
    "input_shape = (250, 21)\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "# Create and compile the model\n",
    "tcn_model = TCN(input_shape, num_classes, num_filters=16, kernel_size=3, dilation_rates=[1, 2], dropout_rate=0.1)\n",
    "tcn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "tcn_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f8551-5737-4fb9-b87a-05ce9a9f8c69",
   "metadata": {},
   "source": [
    "## Step 8: Training and Testing of the TSCeption Model\n",
    "### Objective: Train the TSCeption model using the preprocessed EEG data\n",
    "\n",
    "Explanation: The model is trained using the training data, and its performance is validated on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfa4669c-a8c4-45af-934e-d3c3eba81a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 101ms/step - accuracy: 0.8314 - loss: 0.3861 - val_accuracy: 0.8504 - val_loss: 0.3592\n",
      "Epoch 2/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 107ms/step - accuracy: 0.8349 - loss: 0.3820 - val_accuracy: 0.8704 - val_loss: 0.3306\n",
      "Epoch 3/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 107ms/step - accuracy: 0.8368 - loss: 0.3757 - val_accuracy: 0.8589 - val_loss: 0.3396\n",
      "Epoch 4/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - accuracy: 0.8442 - loss: 0.3638 - val_accuracy: 0.8648 - val_loss: 0.3219\n",
      "Epoch 5/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8449 - loss: 0.3628 - val_accuracy: 0.8693 - val_loss: 0.3250\n",
      "Epoch 6/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8483 - loss: 0.3559 - val_accuracy: 0.8789 - val_loss: 0.3141\n",
      "Epoch 7/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8482 - loss: 0.3542 - val_accuracy: 0.8749 - val_loss: 0.3069\n",
      "Epoch 8/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 99ms/step - accuracy: 0.8480 - loss: 0.3485 - val_accuracy: 0.8786 - val_loss: 0.3004\n",
      "Epoch 9/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8524 - loss: 0.3412 - val_accuracy: 0.8734 - val_loss: 0.3252\n",
      "Epoch 10/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 101ms/step - accuracy: 0.8553 - loss: 0.3333 - val_accuracy: 0.8786 - val_loss: 0.3019\n",
      "Epoch 11/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 97ms/step - accuracy: 0.8615 - loss: 0.3283 - val_accuracy: 0.8789 - val_loss: 0.2976\n",
      "Epoch 12/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8579 - loss: 0.3282 - val_accuracy: 0.8804 - val_loss: 0.2842\n",
      "Epoch 13/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 99ms/step - accuracy: 0.8617 - loss: 0.3269 - val_accuracy: 0.8752 - val_loss: 0.2970\n",
      "Epoch 14/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8549 - loss: 0.3247 - val_accuracy: 0.8648 - val_loss: 0.3161\n",
      "Epoch 15/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 95ms/step - accuracy: 0.8592 - loss: 0.3199 - val_accuracy: 0.8711 - val_loss: 0.2993\n",
      "Epoch 16/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8652 - loss: 0.3134 - val_accuracy: 0.8797 - val_loss: 0.2829\n",
      "Epoch 17/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8608 - loss: 0.3199 - val_accuracy: 0.8804 - val_loss: 0.2863\n",
      "Epoch 18/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 94ms/step - accuracy: 0.8638 - loss: 0.3219 - val_accuracy: 0.8845 - val_loss: 0.2723\n",
      "Epoch 19/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 100ms/step - accuracy: 0.8715 - loss: 0.3008 - val_accuracy: 0.8841 - val_loss: 0.2765\n",
      "Epoch 20/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 102ms/step - accuracy: 0.8690 - loss: 0.3054 - val_accuracy: 0.8756 - val_loss: 0.2883\n",
      "Epoch 21/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 98ms/step - accuracy: 0.8676 - loss: 0.3022 - val_accuracy: 0.8827 - val_loss: 0.2721\n",
      "Epoch 22/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 103ms/step - accuracy: 0.8683 - loss: 0.3042 - val_accuracy: 0.8849 - val_loss: 0.2667\n",
      "Epoch 23/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8699 - loss: 0.2980 - val_accuracy: 0.8760 - val_loss: 0.2836\n",
      "Epoch 24/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8735 - loss: 0.3040 - val_accuracy: 0.8856 - val_loss: 0.2650\n",
      "Epoch 25/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 91ms/step - accuracy: 0.8716 - loss: 0.2962 - val_accuracy: 0.8849 - val_loss: 0.2634\n",
      "Epoch 26/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8742 - loss: 0.2896 - val_accuracy: 0.8875 - val_loss: 0.2656\n",
      "Epoch 27/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8763 - loss: 0.2850 - val_accuracy: 0.8782 - val_loss: 0.2798\n",
      "Epoch 28/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8658 - loss: 0.3012 - val_accuracy: 0.8849 - val_loss: 0.2601\n",
      "Epoch 29/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 102ms/step - accuracy: 0.8718 - loss: 0.2906 - val_accuracy: 0.8834 - val_loss: 0.2683\n",
      "Epoch 30/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8775 - loss: 0.2803 - val_accuracy: 0.8853 - val_loss: 0.2615\n",
      "Epoch 31/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 103ms/step - accuracy: 0.8737 - loss: 0.2951 - val_accuracy: 0.8845 - val_loss: 0.2665\n",
      "Epoch 32/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8724 - loss: 0.2895 - val_accuracy: 0.8871 - val_loss: 0.2576\n",
      "Epoch 33/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 102ms/step - accuracy: 0.8766 - loss: 0.2837 - val_accuracy: 0.8793 - val_loss: 0.2833\n",
      "Epoch 34/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 97ms/step - accuracy: 0.8815 - loss: 0.2760 - val_accuracy: 0.8879 - val_loss: 0.2592\n",
      "Epoch 35/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8793 - loss: 0.2763 - val_accuracy: 0.8890 - val_loss: 0.2590\n",
      "Epoch 36/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8786 - loss: 0.2767 - val_accuracy: 0.8841 - val_loss: 0.2616\n",
      "Epoch 37/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 101ms/step - accuracy: 0.8799 - loss: 0.2785 - val_accuracy: 0.8860 - val_loss: 0.2629\n",
      "Epoch 38/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8735 - loss: 0.2859 - val_accuracy: 0.8905 - val_loss: 0.2552\n",
      "Epoch 39/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8779 - loss: 0.2759 - val_accuracy: 0.8804 - val_loss: 0.2708\n",
      "Epoch 40/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8788 - loss: 0.2765 - val_accuracy: 0.8875 - val_loss: 0.2564\n",
      "Epoch 41/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8726 - loss: 0.2764 - val_accuracy: 0.8897 - val_loss: 0.2532\n",
      "Epoch 42/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 102ms/step - accuracy: 0.8829 - loss: 0.2700 - val_accuracy: 0.8897 - val_loss: 0.2555\n",
      "Epoch 43/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 102ms/step - accuracy: 0.8787 - loss: 0.2741 - val_accuracy: 0.8856 - val_loss: 0.2569\n",
      "Epoch 44/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8790 - loss: 0.2770 - val_accuracy: 0.8905 - val_loss: 0.2512\n",
      "Epoch 45/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 99ms/step - accuracy: 0.8827 - loss: 0.2727 - val_accuracy: 0.8864 - val_loss: 0.2615\n",
      "Epoch 46/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8823 - loss: 0.2721 - val_accuracy: 0.8834 - val_loss: 0.2660\n",
      "Epoch 47/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 111ms/step - accuracy: 0.8850 - loss: 0.2633 - val_accuracy: 0.8905 - val_loss: 0.2502\n",
      "Epoch 48/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8830 - loss: 0.2651 - val_accuracy: 0.8834 - val_loss: 0.2725\n",
      "Epoch 49/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 101ms/step - accuracy: 0.8809 - loss: 0.2712 - val_accuracy: 0.8919 - val_loss: 0.2501\n",
      "Epoch 50/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 101ms/step - accuracy: 0.8862 - loss: 0.2636 - val_accuracy: 0.8931 - val_loss: 0.2477\n",
      "Epoch 51/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 109ms/step - accuracy: 0.8816 - loss: 0.2678 - val_accuracy: 0.8893 - val_loss: 0.2557\n",
      "Epoch 52/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 97ms/step - accuracy: 0.8777 - loss: 0.2801 - val_accuracy: 0.8905 - val_loss: 0.2492\n",
      "Epoch 53/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 97ms/step - accuracy: 0.8809 - loss: 0.2649 - val_accuracy: 0.8893 - val_loss: 0.2554\n",
      "Epoch 54/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8891 - loss: 0.2520 - val_accuracy: 0.8890 - val_loss: 0.2534\n",
      "Epoch 55/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8871 - loss: 0.2565 - val_accuracy: 0.8942 - val_loss: 0.2485\n",
      "Epoch 56/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8822 - loss: 0.2633 - val_accuracy: 0.8938 - val_loss: 0.2463\n",
      "Epoch 57/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8853 - loss: 0.2597 - val_accuracy: 0.8953 - val_loss: 0.2414\n",
      "Epoch 58/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 97ms/step - accuracy: 0.8872 - loss: 0.2520 - val_accuracy: 0.8916 - val_loss: 0.2453\n",
      "Epoch 59/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8870 - loss: 0.2609 - val_accuracy: 0.8931 - val_loss: 0.2431\n",
      "Epoch 60/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 99ms/step - accuracy: 0.8863 - loss: 0.2583 - val_accuracy: 0.8927 - val_loss: 0.2432\n",
      "Epoch 61/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8799 - loss: 0.2620 - val_accuracy: 0.8845 - val_loss: 0.2598\n",
      "Epoch 62/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8879 - loss: 0.2575 - val_accuracy: 0.8912 - val_loss: 0.2443\n",
      "Epoch 63/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8837 - loss: 0.2618 - val_accuracy: 0.8905 - val_loss: 0.2524\n",
      "Epoch 64/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8845 - loss: 0.2663 - val_accuracy: 0.8864 - val_loss: 0.2580\n",
      "Epoch 65/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 101ms/step - accuracy: 0.8868 - loss: 0.2588 - val_accuracy: 0.8916 - val_loss: 0.2486\n",
      "Epoch 66/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8877 - loss: 0.2540 - val_accuracy: 0.8931 - val_loss: 0.2466\n",
      "Epoch 67/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8840 - loss: 0.2585 - val_accuracy: 0.8942 - val_loss: 0.2424\n",
      "Epoch 68/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8847 - loss: 0.2549 - val_accuracy: 0.8871 - val_loss: 0.2539\n",
      "Epoch 69/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8859 - loss: 0.2522 - val_accuracy: 0.8934 - val_loss: 0.2450\n",
      "Epoch 70/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8841 - loss: 0.2614 - val_accuracy: 0.8938 - val_loss: 0.2438\n",
      "Epoch 71/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 96ms/step - accuracy: 0.8799 - loss: 0.2785 - val_accuracy: 0.8934 - val_loss: 0.2475\n",
      "Epoch 72/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8898 - loss: 0.2511 - val_accuracy: 0.8856 - val_loss: 0.2603\n",
      "Epoch 73/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 97ms/step - accuracy: 0.8882 - loss: 0.2517 - val_accuracy: 0.8860 - val_loss: 0.2552\n",
      "Epoch 74/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8878 - loss: 0.2515 - val_accuracy: 0.8942 - val_loss: 0.2444\n",
      "Epoch 75/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8845 - loss: 0.2578 - val_accuracy: 0.8882 - val_loss: 0.2524\n",
      "Epoch 76/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8863 - loss: 0.2553 - val_accuracy: 0.8901 - val_loss: 0.2514\n",
      "Epoch 77/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8822 - loss: 0.2661 - val_accuracy: 0.8838 - val_loss: 0.2612\n",
      "Epoch 78/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8796 - loss: 0.2661 - val_accuracy: 0.8964 - val_loss: 0.2376\n",
      "Epoch 79/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8865 - loss: 0.2523 - val_accuracy: 0.8912 - val_loss: 0.2459\n",
      "Epoch 80/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 97ms/step - accuracy: 0.8892 - loss: 0.2493 - val_accuracy: 0.8923 - val_loss: 0.2467\n",
      "Epoch 81/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 98ms/step - accuracy: 0.8859 - loss: 0.2522 - val_accuracy: 0.8964 - val_loss: 0.2362\n",
      "Epoch 82/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 99ms/step - accuracy: 0.8916 - loss: 0.2448 - val_accuracy: 0.8953 - val_loss: 0.2409\n",
      "Epoch 83/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 98ms/step - accuracy: 0.8944 - loss: 0.2428 - val_accuracy: 0.8964 - val_loss: 0.2359\n",
      "Epoch 84/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8870 - loss: 0.2516 - val_accuracy: 0.8908 - val_loss: 0.2491\n",
      "Epoch 85/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 95ms/step - accuracy: 0.8891 - loss: 0.2526 - val_accuracy: 0.8942 - val_loss: 0.2458\n",
      "Epoch 86/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8905 - loss: 0.2543 - val_accuracy: 0.8957 - val_loss: 0.2401\n",
      "Epoch 87/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8831 - loss: 0.2645 - val_accuracy: 0.8916 - val_loss: 0.2453\n",
      "Epoch 88/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 94ms/step - accuracy: 0.8855 - loss: 0.2527 - val_accuracy: 0.8953 - val_loss: 0.2437\n",
      "Epoch 89/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8875 - loss: 0.2542 - val_accuracy: 0.8942 - val_loss: 0.2423\n",
      "Epoch 90/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8890 - loss: 0.2461 - val_accuracy: 0.8938 - val_loss: 0.2402\n",
      "Epoch 91/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 97ms/step - accuracy: 0.8889 - loss: 0.2501 - val_accuracy: 0.8953 - val_loss: 0.2375\n",
      "Epoch 92/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8885 - loss: 0.2552 - val_accuracy: 0.8938 - val_loss: 0.2369\n",
      "Epoch 93/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8839 - loss: 0.2495 - val_accuracy: 0.8890 - val_loss: 0.2568\n",
      "Epoch 94/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8914 - loss: 0.2488 - val_accuracy: 0.8953 - val_loss: 0.2370\n",
      "Epoch 95/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - accuracy: 0.8847 - loss: 0.2526 - val_accuracy: 0.8953 - val_loss: 0.2432\n",
      "Epoch 96/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 94ms/step - accuracy: 0.8872 - loss: 0.2507 - val_accuracy: 0.8942 - val_loss: 0.2423\n",
      "Epoch 97/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 96ms/step - accuracy: 0.8878 - loss: 0.2503 - val_accuracy: 0.8934 - val_loss: 0.2430\n",
      "Epoch 98/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 96ms/step - accuracy: 0.8855 - loss: 0.2510 - val_accuracy: 0.8953 - val_loss: 0.2385\n",
      "Epoch 99/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - accuracy: 0.8868 - loss: 0.2505 - val_accuracy: 0.8957 - val_loss: 0.2388\n",
      "Epoch 100/100\n",
      "\u001b[1m337/337\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 98ms/step - accuracy: 0.8863 - loss: 0.2508 - val_accuracy: 0.8960 - val_loss: 0.2601\n"
     ]
    }
   ],
   "source": [
    "history = tcn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c0899f2-9783-428c-8564-ea0bd78da4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2600855231285095\n",
      "Test accuracy: 0.8960267305374146\n"
     ]
    }
   ],
   "source": [
    "score = tcn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d73b2-593b-4fda-a950-7a696a8a3e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
